## Module 1: Introduction to unsupervised learning and K-means
### Overview
Unsupervised learning: you do not know the outcomes 
Types of Unsupervised learning 
- Clustering: identify unknown structure in data
	- Helps identify groups of similar customers
	- Examples: 
		- K-means, Hierarchical Agglomerative Clustering, DBSCAN, Mean Shift
- Dimensionality Reduction: use structural characteristics to simplify data
	- Can improve both the performance and interpretability of grouping
	- Examples:
	- Principal Component Analysis
	- Non-negative Matrix Factorisation

Flow: 
unlabeled data --fit-> model
new unlabeled data + model --predict-> map new data to model
hel
### Clustering
Use Cases: 
- spam filter, unlabeled data, anomaly detection, customer segmentation
- improve supervised learning

### K-Means
K -> how many clusters there are
#### How it works [[K-Means-Diagram]]:
Pick 2 random points
Then select closest ones, then move to the mean of all the points
While the mean changes: 
	Move clusters to nearest centroid
	Move centroid the new mean of all points

#### Smart initialisation
Pick one random point as initial. Then for next culsteroid select with $distance(xi)$
$$
\frac{\operatorname{distance}(x_i^2)}
     {\left( \sum_i \operatorname{distance}(x_i) \right)^2}
$$

## Dimensionality Reduction
Use Cases: 
- image processing
- image tracking