## Module 1: Introduction to unsupervised learning and K-means
### Overview
Unsupervised learning: you do not know the outcomes 
Types of Unsupervised learning 
- Clustering: identify unknown structure in data
	- Helps identify groups of similar customers
	- Examples: 
		- K-means, Hierarchical Agglomerative Clustering, DBSCAN, Mean Shift
- Dimensionality Reduction: use structural characteristics to simplify data
	- Can improve both the performance and interpretability of grouping
	- Examples:
	- Principal Component Analysis
	- Non-negative Matrix Factorisation

Flow: 
unlabeled data --fit-> model
new unlabeled data + model --predict-> map new data to model
hel
### Clustering
Use Cases: 
- spam filter, unlabeled data, anomaly detection, customer segmentation
- improve supervised learning

#### K-Means
K -> how many clusters there are
#### How it works [[4.1 K-Means-Diagram]]:
Pick 2 random points
Then select closest ones, then move to the mean of all the points
While the mean changes: 
	Move clusters to nearest centroid
	Move centroid the new mean of all points

#### Smart Initialisation - K means++
Pick one random point as initial. Then for next cluster centroid select with:
$$
prob = \frac{\operatorname{distance}(x_i)^2}
     {\left( \sum_{i=1}^{n} \operatorname{distance}(x_i) \right)^2}
$$
Rewards furthest distance from all centroids. 

#### How to choose K:
- choose based on how many clusters you need (eg 10 groups)
- ##### INERTIA: 
	- sum of squared distance from each point to its cluster $\sum_{i=1}^{n} (x_i-C_k)^2$
	- smaller value corresponds to tighter clusters 
	- value sensitive to number of points in clusters, increases as more points added
	- USE WHEN clusters have similar number of points
- ##### DISTORTION: 
	- average of squared distance from each point $x_i$ to its cluster $C_k$ $\frac{1}{n}\sum_{i=1}^{n} (x_i-c_k)^2$
	- smaller values correspond to tighter clusters
	- doesn't generally increase as more points are added (relvative to inertia)
	- USE WHEN similarity is more important 
- Create a graph and use elbow method based on inertia or distortion
## Dimensionality Reduction
Use Cases: 
- image processing
- image tracking